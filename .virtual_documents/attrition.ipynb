


# Import our dependencies
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd
import numpy as np
from tensorflow.keras.models import Model
from tensorflow.keras import layers

#  Import and read the attrition data
attrition_df = pd.read_csv('https://static.bc-edx.com/ai/ail-v-1-0/m19/lms/datasets/attrition.csv')
attrition_df.head()


# Determine the number of unique values in each column.
attrition_df.nunique()


# Create y_df with the Attrition and Department columns
y_df = attrition_df[['Attrition', 'Department']]



# Create a list of at least 10 column names to use as X data

X_columns = ["Education", 
             "Age", 
             "DistanceFromHome", 
             "JobSatisfaction", 
             "TotalWorkingYears", 
             "WorkLifeBalance", 
             "YearsAtCompany",  
             "YearsSinceLastPromotion", 
             "NumCompaniesWorked", 
             "YearsWithCurrManager", ]   

# Create X_df using your selected columns
X_df = attrition_df[X_columns]

# Show the data types for X_df
X_df.dtypes


# Split the data into training and testing sets
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=42)



# Convert your X data to numeric data types however you see fit
# Add new code cells as necessary



# Create a StandardScaler
scaler = StandardScaler()

# Fit the StandardScaler to the training data
scaler.fit(X_train)

# Scale the training data
X_train_scaled = scaler.transform(X_train)

# Scale the testing data
X_test_scaled = scaler.transform(X_test)

# Display the first few rows of the scaled training data to verify
X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)
print(X_train_scaled_df.head())



# Create a OneHotEncoder for the Department column
department_ohe = OneHotEncoder(drop=None, handle_unknown='ignore', sparse_output=False)

# Fit the encoder to the training data
department_ohe.fit(np.array(y_train['Department']).reshape(-1, 1))

# Create two new variables by applying the encoder
# to the training and testing data
# Transform both the training and testing data
y_train_department_encoded = department_ohe.transform(np.array(y_train['Department']).reshape(-1, 1))
y_test_department_encoded = department_ohe.transform(np.array(y_test['Department']).reshape(-1, 1))

# Display results
print("Training Data with Encoded Department:")
print(y_train_department_encoded[:5])

print("\nTesting Data with Encoded Department:")
print(y_test_department_encoded[:5])



# Create a OneHotEncoder for the Attrition column
attrition_ohe = OneHotEncoder(drop=None, handle_unknown='ignore', sparse_output=False)

# Fit the encoder to the training data
attrition_ohe.fit(np.array(y_train['Attrition']).reshape(-1, 1))

# Create two new variables by applying the encoder
# to the training and testing data
y_train_attrition_encoded = attrition_ohe.transform(np.array(y_train['Attrition']).reshape(-1, 1))
y_test_attrition_encoded = attrition_ohe.transform(np.array(y_test['Attrition']).reshape(-1, 1))

# Display results
print("Training Data with Encoded Attrition:")
print(y_train_attrition_encoded[:5])

print("\nTesting Data with Encoded Attrition:")
print(y_test_attrition_encoded[:5])







# Find the number of columns in the X training data
input_features = X_train_scaled.shape[1]

# Create the input layer
input_layer = layers.Input(shape=(input_features,))

# Create at least two shared layers
shared_layer_1 = layers.Dense(64, activation='relu')(input_layer)
shared_layer_2 = layers.Dense(32, activation='relu')(shared_layer_1)



# Create a branch for the Department
# with a hidden layer and an output layer
# Create the input layer for the Department
department_input = layers.Input(shape=(y_train_department_encoded.shape[1],))
# Create the hidden layer
dept_hidden_layer = layers.Dense(16, activation='relu')(department_input)
dept_output_layer = layers.Dense(y_train_department_encoded.shape[1], activation='softmax', name='department_output')(dept_hidden_layer)




# Create a branch for Attrition
# with a hidden layer and an output layer

# Create the hidden layer


# Create the output layer




# Create the model


# Compile the model


# Summarize the model



# Train the model




# Evaluate the model with the testing data



# Print the accuracy for both department and attrition










