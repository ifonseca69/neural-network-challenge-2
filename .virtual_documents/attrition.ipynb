


# Import our dependencies
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd
import numpy as np
from tensorflow.keras.models import Model
from tensorflow.keras import layers

#  Import and read the attrition data
attrition_df = pd.read_csv('https://static.bc-edx.com/ai/ail-v-1-0/m19/lms/datasets/attrition.csv')
attrition_df.head()


# Determine the number of unique values in each column.
attrition_df.nunique()


# Create y_df with the Attrition and Department columns




# Create a list of at least 10 column names to use as X data



# Create X_df using your selected columns


# Show the data types for X_df




# Split the data into training and testing sets
from sklearn.model_selection import train_test_split




# Convert your X data to numeric data types however you see fit
# Add new code cells as necessary



# Create a StandardScaler


# Fit the StandardScaler to the training data


# Scale the training and testing data




# Create a OneHotEncoder for the Department column


# Fit the encoder to the training data


# Create two new variables by applying the encoder
# to the training and testing data





# Create a OneHotEncoder for the Attrition column


# Fit the encoder to the training data


# Create two new variables by applying the encoder
# to the training and testing data







# Find the number of columns in the X training data


# Create the input layer


# Create at least two shared layers



# Create a branch for Department
# with a hidden layer and an output layer

# Create the hidden layer


# Create the output layer




# Create a branch for Attrition
# with a hidden layer and an output layer

# Create the hidden layer


# Create the output layer




# Create the model


# Compile the model


# Summarize the model



# Train the model




# Evaluate the model with the testing data



# Print the accuracy for both department and attrition










